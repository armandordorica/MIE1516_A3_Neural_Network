{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# (E8) Classification of MNIST Hand-written Digits\n",
    "In this exercise, you will be given an example of [MNIST classification](http://yann.lecun.com/exdb/mnist/). \n",
    "You should be able to replicate the results given here if you have completed (E2)-(E5) correctly.\n",
    "\n",
    "It would be best if you have a Python IDE (integrated development environment) such as [PyCharm](https://www.jetbrains.com/pycharm/) and [Anaconda](anaconda.com) is installed because they will make your life easier! If not, you may want to work on the assignment using Google Colab. In any cases, what you need to do is 1) to fill in the blanks in .py files; and 2) to import the files (e.g., layer.py, optim.py, model.py, etc) that you have completed for use. Here are some scenarios how you would go about doing the assignment: \n",
    "\n",
    "#### Without Google Colab: Python IDE + Anaconda \n",
    "If you have a Python IDE and Anaconda installed, you can do one of the following:\n",
    "- Edit .py files in the IDE. Then, simply open .ipynb file also in the IDE where you can edit and run codes. \n",
    "- Your IDE might not support running .ipynb files. However, since you have installed Anaconda, you can just open this notebook using Jupyter Notebook.\n",
    "\n",
    "In both of these cases, you can simply import .py files in this .ipynb file:\n",
    "```python\n",
    "from model import NeuralNetwork\n",
    "```\n",
    " \n",
    "#### With Google Colab\n",
    "- Google Colab has an embedded code editor. So, you could simply upload all .py files to Google Colab and edit the files there. Once you upload the files, double click a file that you want to edit. Please **make sure that you download up-to-date files frequently**, otherwise Google Colab might accidentally restart and all your files might be gone.\n",
    "- If you feel like the above way is cumbersome, you could instead use any online Python editors for completing .py files (e.g., see [repl.it](https://repl.it/languages/python3)). Also, it's not impossible that you edit the files using any text editors, but they don't show you essential Python grammar information, so you'll be prone to make mistakes in that case. Once you are done editing, you can either upload the files to Colab or follow the instruction below. \n",
    " \n",
    "- If you have *git clone*d the assignment repository to a directory in your Google Drive (or you have the files stored in the Drive anyway), you can do the following:\n",
    "```jupyterpython\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')          # this will direct you to a link where you can get an authorization key\n",
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/your-directory-where-the-python-files-exist')\n",
    "```\n",
    "Then, you are good to go. When you change a .py file, make sure it is synced to the drive, then you need to re-run the above lines to get access to the latest version of the file. Note that you should give correct path to *sys.path.append* method.\n",
    "\n",
    "Now, let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dataset\n",
    "MNIST dataset has been one of the most frequently used dataset. Among the total of 70,000 (28x28) images, 60,000 are used for training, while 10,000 are reserved for testing. The images have only 1 channel (hence, black and white), and each pixel has a value between 0 to 255 (integers). The labels are also integers which indicate the number written in the corresponding images. Often, the class labels are one-hot encoded during preprocessing.\n",
    "\n",
    "Some simple preprocessing like below is normally done on the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np\n",
    "np.random.seed(100)                         # fix a random seed for reproducibility\n",
    "\n",
    "# download the dataset (this will take some time)\n",
    "mnist = fetch_openml('mnist_784', cache=False)\n",
    "num_train = 60000\n",
    "image = mnist.data\n",
    "label = mnist.target.astype('int64')\n",
    "\n",
    "# normalize pixel values to (-0.5, 0.5) range\n",
    "image = image / 255 - 0.5\n",
    "\n",
    "# train test split\n",
    "train_image, train_label, test_image, test_label = \\\n",
    "        image[:num_train], label[:num_train], image[num_train:], label[num_train:]\n",
    "\n",
    "# One-hot encoding\n",
    "train_label, test_label = np.eye(10)[train_label], np.eye(10)[test_label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Logistic Regression\n",
    "Let's define a linear neural network model which has no hidden layers. Since we are solving a classification problem, we need to use the softmax output and the cross entropy loss. Note that this reduces to the logistic regression!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import files\n",
    "from model import NeuralNetwork\n",
    "from layer import FCLayer\n",
    "from loss import CrossEntropyLoss\n",
    "from optim import SGD, Adam, RMSProp\n",
    "from utils import *\n",
    "\n",
    "nn = NeuralNetwork()\n",
    "nn.add(FCLayer(train_image.shape[1], train_label.shape[1], initialization='xavier', uniform=True))  # no hidden layers. direct mapping from input images to target labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set loss and link to the model\n",
    "loss = CrossEntropyLoss()\n",
    "nn.set_loss(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set hyperparamters\n",
    "lr = 0.001                                  # learning rate\n",
    "batch_size = 32                             # mini-batch size\n",
    "epochs = 5                                  # number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# set optimizer and link to the model\n",
    "optimizer = Adam(nn.parameters(), lr=lr)\n",
    "nn.set_optimizer(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/5\terror=0.01474\t\n",
      "Epoch 1/5\terror=0.01474\tTest accuracy: 0.8972Test accuracy: 0.8972\n",
      "Epoch 2/5\terror=0.00996\t\n",
      "Epoch 2/5\terror=0.00996\tTest accuracy: 0.9128Test accuracy: 0.9128\n",
      "Epoch 3/5\terror=0.00990\t\n",
      "Epoch 3/5\terror=0.00990\tTest accuracy: 0.9146Test accuracy: 0.9146\n",
      "Epoch 4/5\terror=0.00921\t\n",
      "Epoch 4/5\terror=0.00921\tTest accuracy: 0.9168Test accuracy: 0.9168\n",
      "Epoch 5/5\terror=0.01014\t\n",
      "Epoch 5/5\terror=0.01014\tTest accuracy: 0.9151Test accuracy: 0.9151"
     ]
    }
   ],
   "source": [
    "inds = list(range(train_image.shape[0]))\n",
    "N = train_image.shape[0]                               # number of training samples\n",
    "\n",
    "loss_hist = []\n",
    "for epoch in range(epochs):\n",
    "    # randomly shuffle the training data at the beginning of each epoch\n",
    "    inds = np.random.permutation(inds)\n",
    "    x_train = train_image[inds]\n",
    "    y_train = train_label[inds]\n",
    "\n",
    "    loss = 0\n",
    "    for b in range(0, N, batch_size):\n",
    "        # get the mini-batch\n",
    "        x_batch = x_train[b: b + batch_size]\n",
    "        y_batch = y_train[b: b + batch_size]\n",
    "\n",
    "        # feed forward\n",
    "        pred = nn.predict(x_batch)\n",
    "\n",
    "        # Error\n",
    "        loss += nn.loss(pred, y_batch) / N\n",
    "\n",
    "        # Back propagation of errors\n",
    "        nn.backward(pred, y_batch)\n",
    "\n",
    "        # Update parameters\n",
    "        nn.optimizer.step()\n",
    "\n",
    "    # record loss per epoch\n",
    "    loss_hist.append(loss)\n",
    "\n",
    "    print()\n",
    "    print(\"Epoch %d/%d\\terror=%.5f\" % (epoch + 1, epochs, loss), end='\\t', flush=True)\n",
    "\n",
    "    # Test accuracy\n",
    "    pred = softmax(nn.predict(test_image, mode=False))\n",
    "    y_pred, y_target = np.argmax(pred, axis=1), np.argmax(test_label, axis=1)\n",
    "    accuracy = np.mean(y_pred == y_target)\n",
    "    print(\"Test accuracy: {:.4f}\".format(accuracy), end='')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## (E8) Your Turn: Non-linear Neural Network\n",
    "Surprisingly, the model achieved more than 91% test accuracy. However, you can definitely improve the test performance by, for example, introducing nonlinear activation functions, changing the network architecture, adjusting the learning rate, training more epochs, and (or) using a different optimizer. **It's your turn to try different configurations of these!** \n",
    "\n",
    "*Experiment with more than 3 configurations of these to get better test performance, and report your trials by summarizing the configurations and performance in a **table**. (You can achieve *at least* 96% accuracy pretty easily.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increasing epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from activation import Activation\n",
    "from utils import *\n",
    "\n",
    "nn = NeuralNetwork()\n",
    "\n",
    "nn.add(FCLayer(train_image.shape[1], train_label.shape[1], initialization='xavier', uniform=True))  # no hidden layers. direct mapping from input images to target labels\n",
    "\n",
    "# Set loss and link to the model\n",
    "loss = CrossEntropyLoss()\n",
    "nn.set_loss(loss)\n",
    "\n",
    "# Set hyperparamters\n",
    "lr = 0.001                                  # learning rate\n",
    "batch_size = 32                             # mini-batch size\n",
    "epochs = 10                                  # number of epochs\n",
    "\n",
    "# set optimizer and link to the model\n",
    "optimizer = Adam(nn.parameters(), lr=lr)\n",
    "nn.set_optimizer(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\terror=0.01592\t\n",
      "Epoch 1/10\terror=0.01592\tTest accuracy: 0.9083Test accuracy: 0.9083\n",
      "Epoch 2/10\terror=0.01015\t\n",
      "Epoch 2/10\terror=0.01015\tTest accuracy: 0.9078Test accuracy: 0.9078\n",
      "Epoch 3/10\terror=0.00947\t\n",
      "Epoch 3/10\terror=0.00947\tTest accuracy: 0.9141Test accuracy: 0.9141\n",
      "Epoch 4/10\terror=0.00902\t\n",
      "Epoch 4/10\terror=0.00902\tTest accuracy: 0.9203Test accuracy: 0.9203\n",
      "Epoch 5/10\terror=0.00905\t\n",
      "Epoch 5/10\terror=0.00905\tTest accuracy: 0.9142Test accuracy: 0.9142\n",
      "Epoch 6/10\terror=0.00839\t\n",
      "Epoch 6/10\terror=0.00839\tTest accuracy: 0.9079Test accuracy: 0.9079\n",
      "Epoch 7/10\terror=0.00932\t\n",
      "Epoch 7/10\terror=0.00932\tTest accuracy: 0.9177Test accuracy: 0.9177\n",
      "Epoch 8/10\terror=0.00865\t\n",
      "Epoch 8/10\terror=0.00865\tTest accuracy: 0.9164Test accuracy: 0.9164\n",
      "Epoch 9/10\terror=0.00872\t\n",
      "Epoch 9/10\terror=0.00872\tTest accuracy: 0.9175Test accuracy: 0.9175\n",
      "Epoch 10/10\terror=0.00876\t\n",
      "Epoch 10/10\terror=0.00876\tTest accuracy: 0.9204Test accuracy: 0.9204"
     ]
    }
   ],
   "source": [
    "inds = list(range(train_image.shape[0]))\n",
    "N = train_image.shape[0]                               # number of training samples\n",
    "\n",
    "loss_hist_1 = []\n",
    "for epoch in range(epochs):\n",
    "    # randomly shuffle the training data at the beginning of each epoch\n",
    "    inds = np.random.permutation(inds)\n",
    "    x_train = train_image[inds]\n",
    "    y_train = train_label[inds]\n",
    "\n",
    "    loss = 0\n",
    "    for b in range(0, N, batch_size):\n",
    "        # get the mini-batch\n",
    "        x_batch = x_train[b: b + batch_size]\n",
    "        y_batch = y_train[b: b + batch_size]\n",
    "\n",
    "        # feed forward\n",
    "        pred = nn.predict(x_batch)\n",
    "\n",
    "        # Error\n",
    "        loss += nn.loss(pred, y_batch) / N\n",
    "\n",
    "        # Back propagation of errors\n",
    "        nn.backward(pred, y_batch)\n",
    "\n",
    "        # Update parameters\n",
    "        nn.optimizer.step()\n",
    "\n",
    "    # record loss per epoch\n",
    "    loss_hist_1.append(loss)\n",
    "\n",
    "    print()\n",
    "    print(\"Epoch %d/%d\\terror=%.5f\" % (epoch + 1, epochs, loss), end='\\t', flush=True)\n",
    "\n",
    "    # Test accuracy\n",
    "    pred = softmax(nn.predict(test_image, mode=False))\n",
    "    y_pred, y_target = np.argmax(pred, axis=1), np.argmax(test_label, axis=1)\n",
    "    accuracy = np.mean(y_pred == y_target)\n",
    "    print(\"Test accuracy: {:.4f}\".format(accuracy), end='')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from activation import Activation\n",
    "from utils import *\n",
    "\n",
    "nn = NeuralNetwork()\n",
    "\n",
    "nn.add(FCLayer(train_image.shape[1], train_label.shape[1], initialization='xavier', uniform=True))  # no hidden layers. direct mapping from input images to target labels\n",
    "nn.add(Activation(relu, relu_prime))\n",
    "\n",
    "# Set loss and link to the model\n",
    "loss = CrossEntropyLoss()\n",
    "nn.set_loss(loss)\n",
    "\n",
    "# Set hyperparamters\n",
    "lr = 0.001                                  # learning rate\n",
    "batch_size = 32                             # mini-batch size\n",
    "epochs = 10                                  # number of epochs\n",
    "\n",
    "# set optimizer and link to the model\n",
    "optimizer = Adam(nn.parameters(), lr=lr)\n",
    "nn.set_optimizer(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\terror=0.05199\t\n",
      "Epoch 1/10\terror=0.05199\tTest accuracy: 0.4254Test accuracy: 0.4254\n",
      "Epoch 2/10\terror=0.04843\t\n",
      "Epoch 2/10\terror=0.04843\tTest accuracy: 0.4347Test accuracy: 0.4347\n",
      "Epoch 3/10\terror=0.04989\t\n",
      "Epoch 3/10\terror=0.04989\tTest accuracy: 0.4407Test accuracy: 0.4407\n",
      "Epoch 4/10\terror=0.04896\t\n",
      "Epoch 4/10\terror=0.04896\tTest accuracy: 0.4397Test accuracy: 0.4397\n",
      "Epoch 5/10\terror=0.04811\t\n",
      "Epoch 5/10\terror=0.04811\tTest accuracy: 0.4374Test accuracy: 0.4374\n",
      "Epoch 6/10\terror=0.04900\t\n",
      "Epoch 6/10\terror=0.04900\tTest accuracy: 0.4445Test accuracy: 0.4445\n",
      "Epoch 7/10\terror=0.04808\t\n",
      "Epoch 7/10\terror=0.04808\tTest accuracy: 0.4475Test accuracy: 0.4475\n",
      "Epoch 8/10\terror=0.04779\t\n",
      "Epoch 8/10\terror=0.04779\tTest accuracy: 0.4481Test accuracy: 0.4481\n",
      "Epoch 9/10\terror=0.04826\t\n",
      "Epoch 9/10\terror=0.04826\tTest accuracy: 0.4494Test accuracy: 0.4494\n",
      "Epoch 10/10\terror=0.04803\t\n",
      "Epoch 10/10\terror=0.04803\tTest accuracy: 0.4477Test accuracy: 0.4477"
     ]
    }
   ],
   "source": [
    "inds = list(range(train_image.shape[0]))\n",
    "N = train_image.shape[0]                               # number of training samples\n",
    "\n",
    "loss_hist_1 = []\n",
    "for epoch in range(epochs):\n",
    "    # randomly shuffle the training data at the beginning of each epoch\n",
    "    inds = np.random.permutation(inds)\n",
    "    x_train = train_image[inds]\n",
    "    y_train = train_label[inds]\n",
    "\n",
    "    loss = 0\n",
    "    for b in range(0, N, batch_size):\n",
    "        # get the mini-batch\n",
    "        x_batch = x_train[b: b + batch_size]\n",
    "        y_batch = y_train[b: b + batch_size]\n",
    "\n",
    "        # feed forward\n",
    "        pred = nn.predict(x_batch)\n",
    "\n",
    "        # Error\n",
    "        loss += nn.loss(pred, y_batch) / N\n",
    "\n",
    "        # Back propagation of errors\n",
    "        nn.backward(pred, y_batch)\n",
    "\n",
    "        # Update parameters\n",
    "        nn.optimizer.step()\n",
    "\n",
    "    # record loss per epoch\n",
    "    loss_hist_1.append(loss)\n",
    "\n",
    "    print()\n",
    "    print(\"Epoch %d/%d\\terror=%.5f\" % (epoch + 1, epochs, loss), end='\\t', flush=True)\n",
    "\n",
    "    # Test accuracy\n",
    "    pred = softmax(nn.predict(test_image, mode=False))\n",
    "    y_pred, y_target = np.argmax(pred, axis=1), np.argmax(test_label, axis=1)\n",
    "    accuracy = np.mean(y_pred == y_target)\n",
    "    print(\"Test accuracy: {:.4f}\".format(accuracy), end='')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Tanh as activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from activation import Activation\n",
    "from utils import *\n",
    "\n",
    "nn = NeuralNetwork()\n",
    "\n",
    "nn.add(FCLayer(train_image.shape[1], train_label.shape[1], initialization='xavier', uniform=True))  # no hidden layers. direct mapping from input images to target labels\n",
    "nn.add(Activation(tanh, tanh_prime))\n",
    "\n",
    "# Set loss and link to the model\n",
    "loss = CrossEntropyLoss()\n",
    "nn.set_loss(loss)\n",
    "\n",
    "# Set hyperparamters\n",
    "lr = 0.001                                  # learning rate\n",
    "batch_size = 32                             # mini-batch size\n",
    "epochs = 10                                  # number of epochs\n",
    "\n",
    "# set optimizer and link to the model\n",
    "optimizer = Adam(nn.parameters(), lr=lr)\n",
    "nn.set_optimizer(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\terror=0.03523\t\n",
      "Epoch 1/10\terror=0.03523\tTest accuracy: 0.9009Test accuracy: 0.9009\n",
      "Epoch 2/10\terror=0.03193\t\n",
      "Epoch 2/10\terror=0.03193\tTest accuracy: 0.9005Test accuracy: 0.9005\n",
      "Epoch 3/10\terror=0.03166\t\n",
      "Epoch 3/10\terror=0.03166\tTest accuracy: 0.9038Test accuracy: 0.9038\n",
      "Epoch 4/10\terror=0.03205\t\n",
      "Epoch 4/10\terror=0.03205\tTest accuracy: 0.9088Test accuracy: 0.9088\n",
      "Epoch 5/10\terror=0.03111\t\n",
      "Epoch 5/10\terror=0.03111\tTest accuracy: 0.9054Test accuracy: 0.9054\n",
      "Epoch 6/10\terror=0.03119\t\n",
      "Epoch 6/10\terror=0.03119\tTest accuracy: 0.9118Test accuracy: 0.9118\n",
      "Epoch 7/10\terror=0.03079\t\n",
      "Epoch 7/10\terror=0.03079\tTest accuracy: 0.9144Test accuracy: 0.9144\n",
      "Epoch 8/10\terror=0.03083\t\n",
      "Epoch 8/10\terror=0.03083\tTest accuracy: 0.9136Test accuracy: 0.9136\n",
      "Epoch 9/10\terror=0.03065\t\n",
      "Epoch 9/10\terror=0.03065\tTest accuracy: 0.9087Test accuracy: 0.9087\n",
      "Epoch 10/10\terror=0.03056\t\n",
      "Epoch 10/10\terror=0.03056\tTest accuracy: 0.9088Test accuracy: 0.9088"
     ]
    }
   ],
   "source": [
    "inds = list(range(train_image.shape[0]))\n",
    "N = train_image.shape[0]                               # number of training samples\n",
    "\n",
    "loss_hist_3 = []\n",
    "for epoch in range(epochs):\n",
    "    # randomly shuffle the training data at the beginning of each epoch\n",
    "    inds = np.random.permutation(inds)\n",
    "    x_train = train_image[inds]\n",
    "    y_train = train_label[inds]\n",
    "\n",
    "    loss = 0\n",
    "    for b in range(0, N, batch_size):\n",
    "        # get the mini-batch\n",
    "        x_batch = x_train[b: b + batch_size]\n",
    "        y_batch = y_train[b: b + batch_size]\n",
    "\n",
    "        # feed forward\n",
    "        pred = nn.predict(x_batch)\n",
    "\n",
    "        # Error\n",
    "        loss += nn.loss(pred, y_batch) / N\n",
    "\n",
    "        # Back propagation of errors\n",
    "        nn.backward(pred, y_batch)\n",
    "\n",
    "        # Update parameters\n",
    "        nn.optimizer.step()\n",
    "\n",
    "    # record loss per epoch\n",
    "    loss_hist_3.append(loss)\n",
    "\n",
    "    print()\n",
    "    print(\"Epoch %d/%d\\terror=%.5f\" % (epoch + 1, epochs, loss), end='\\t', flush=True)\n",
    "\n",
    "    # Test accuracy\n",
    "    pred = softmax(nn.predict(test_image, mode=False))\n",
    "    y_pred, y_target = np.argmax(pred, axis=1), np.argmax(test_label, axis=1)\n",
    "    accuracy = np.mean(y_pred == y_target)\n",
    "    print(\"Test accuracy: {:.4f}\".format(accuracy), end='')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increasing Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from activation import Activation\n",
    "from utils import *\n",
    "\n",
    "nn = NeuralNetwork()\n",
    "\n",
    "nn.add(FCLayer(train_image.shape[1], train_label.shape[1], initialization='xavier', uniform=True))  # no hidden layers. direct mapping from input images to target labels\n",
    "\n",
    "# Set loss and link to the model\n",
    "loss = CrossEntropyLoss()\n",
    "nn.set_loss(loss)\n",
    "\n",
    "# Set hyperparamters\n",
    "lr = 0.0001                                  # learning rate\n",
    "batch_size = 32                             # mini-batch size\n",
    "epochs = 20                                  # number of epochs\n",
    "\n",
    "# set optimizer and link to the model\n",
    "optimizer = Adam(nn.parameters(), lr=lr)\n",
    "nn.set_optimizer(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\terror=0.03436\t\n",
      "Epoch 1/20\terror=0.03436\tTest accuracy: 0.8543Test accuracy: 0.8543\n",
      "Epoch 2/20\terror=0.01695\t\n",
      "Epoch 2/20\terror=0.01695\tTest accuracy: 0.8822Test accuracy: 0.8822\n",
      "Epoch 3/20\terror=0.01476\t\n",
      "Epoch 3/20\terror=0.01476\tTest accuracy: 0.8935Test accuracy: 0.8935\n",
      "Epoch 4/20\terror=0.01253\t\n",
      "Epoch 4/20\terror=0.01253\tTest accuracy: 0.8993Test accuracy: 0.8993\n",
      "Epoch 5/20\terror=0.01170\t\n",
      "Epoch 5/20\terror=0.01170\tTest accuracy: 0.9046Test accuracy: 0.9046\n",
      "Epoch 6/20\terror=0.01163\t\n",
      "Epoch 6/20\terror=0.01163\tTest accuracy: 0.9047Test accuracy: 0.9047\n",
      "Epoch 7/20\terror=0.01098\t\n",
      "Epoch 7/20\terror=0.01098\tTest accuracy: 0.9079Test accuracy: 0.9079\n",
      "Epoch 8/20\terror=0.01074\t\n",
      "Epoch 8/20\terror=0.01074\tTest accuracy: 0.9095Test accuracy: 0.9095\n",
      "Epoch 9/20\terror=0.01025\t\n",
      "Epoch 9/20\terror=0.01025\tTest accuracy: 0.9111Test accuracy: 0.9111\n",
      "Epoch 10/20\terror=0.01018\t\n",
      "Epoch 10/20\terror=0.01018\tTest accuracy: 0.9124Test accuracy: 0.9124\n",
      "Epoch 11/20\terror=0.00965\t\n",
      "Epoch 11/20\terror=0.00965\tTest accuracy: 0.9130Test accuracy: 0.9130\n",
      "Epoch 12/20\terror=0.01073\t\n",
      "Epoch 12/20\terror=0.01073\tTest accuracy: 0.9130Test accuracy: 0.9130\n",
      "Epoch 13/20\terror=0.01042\t\n",
      "Epoch 13/20\terror=0.01042\tTest accuracy: 0.9136Test accuracy: 0.9136\n",
      "Epoch 14/20\terror=0.00841\t\n",
      "Epoch 14/20\terror=0.00841\tTest accuracy: 0.9153Test accuracy: 0.9153\n",
      "Epoch 15/20\terror=0.00954\t\n",
      "Epoch 15/20\terror=0.00954\tTest accuracy: 0.9148Test accuracy: 0.9148\n",
      "Epoch 16/20\terror=0.00908\t\n",
      "Epoch 16/20\terror=0.00908\tTest accuracy: 0.9168Test accuracy: 0.9168\n",
      "Epoch 17/20\terror=0.00959\t\n",
      "Epoch 17/20\terror=0.00959\tTest accuracy: 0.9171Test accuracy: 0.9171\n",
      "Epoch 18/20\terror=0.00964\t\n",
      "Epoch 18/20\terror=0.00964\tTest accuracy: 0.9164Test accuracy: 0.9164\n",
      "Epoch 19/20\terror=0.00840\t\n",
      "Epoch 19/20\terror=0.00840\tTest accuracy: 0.9169Test accuracy: 0.9169\n",
      "Epoch 20/20\terror=0.00958\t\n",
      "Epoch 20/20\terror=0.00958\tTest accuracy: 0.9175Test accuracy: 0.9175"
     ]
    }
   ],
   "source": [
    "inds = list(range(train_image.shape[0]))\n",
    "N = train_image.shape[0]                               # number of training samples\n",
    "\n",
    "loss_hist_4 = []\n",
    "for epoch in range(epochs):\n",
    "    # randomly shuffle the training data at the beginning of each epoch\n",
    "    inds = np.random.permutation(inds)\n",
    "    x_train = train_image[inds]\n",
    "    y_train = train_label[inds]\n",
    "\n",
    "    loss = 0\n",
    "    for b in range(0, N, batch_size):\n",
    "        # get the mini-batch\n",
    "        x_batch = x_train[b: b + batch_size]\n",
    "        y_batch = y_train[b: b + batch_size]\n",
    "\n",
    "        # feed forward\n",
    "        pred = nn.predict(x_batch)\n",
    "\n",
    "        # Error\n",
    "        loss += nn.loss(pred, y_batch) / N\n",
    "\n",
    "        # Back propagation of errors\n",
    "        nn.backward(pred, y_batch)\n",
    "\n",
    "        # Update parameters\n",
    "        nn.optimizer.step()\n",
    "\n",
    "    # record loss per epoch\n",
    "    loss_hist_4.append(loss)\n",
    "\n",
    "    print()\n",
    "    print(\"Epoch %d/%d\\terror=%.5f\" % (epoch + 1, epochs, loss), end='\\t', flush=True)\n",
    "\n",
    "    # Test accuracy\n",
    "    pred = softmax(nn.predict(test_image, mode=False))\n",
    "    y_pred, y_target = np.argmax(pred, axis=1), np.argmax(test_label, axis=1)\n",
    "    accuracy = np.mean(y_pred == y_target)\n",
    "    print(\"Test accuracy: {:.4f}\".format(accuracy), end='')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Softmax Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from activation import Activation\n",
    "from activation import Dropout\n",
    "\n",
    "from utils import *\n",
    "\n",
    "nn = NeuralNetwork()\n",
    "\n",
    "nn.add(FCLayer(train_image.shape[1], train_label.shape[1], initialization='xavier', uniform=True))  # no hidden layers. direct mapping from input images to target labels\n",
    "nn.add(Activation(sigmoid, sigmoid_prime))\n",
    "\n",
    "# Set loss and link to the model\n",
    "loss = CrossEntropyLoss()\n",
    "nn.set_loss(loss)\n",
    "\n",
    "# Set hyperparamters\n",
    "lr = 0.0001                                  # learning rate\n",
    "batch_size = 32                             # mini-batch size\n",
    "epochs = 20                                  # number of epochs\n",
    "\n",
    "# set optimizer and link to the model\n",
    "optimizer = Adam(nn.parameters(), lr=lr)\n",
    "nn.set_optimizer(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\terror=0.06086\t\n",
      "Epoch 1/20\terror=0.06086\tTest accuracy: 0.8227Test accuracy: 0.8227\n",
      "Epoch 2/20\terror=0.05428\t\n",
      "Epoch 2/20\terror=0.05428\tTest accuracy: 0.8547Test accuracy: 0.8547\n",
      "Epoch 3/20\terror=0.05229\t\n",
      "Epoch 3/20\terror=0.05229\tTest accuracy: 0.8709Test accuracy: 0.8709\n",
      "Epoch 4/20\terror=0.05152\t\n",
      "Epoch 4/20\terror=0.05152\tTest accuracy: 0.8787Test accuracy: 0.8787\n",
      "Epoch 5/20\terror=0.05156\t\n",
      "Epoch 5/20\terror=0.05156\tTest accuracy: 0.8840Test accuracy: 0.8840\n",
      "Epoch 6/20\terror=0.05093\t\n",
      "Epoch 6/20\terror=0.05093\tTest accuracy: 0.8873Test accuracy: 0.8873\n",
      "Epoch 7/20\terror=0.05060\t\n",
      "Epoch 7/20\terror=0.05060\tTest accuracy: 0.8889Test accuracy: 0.8889\n",
      "Epoch 8/20\terror=0.05060\t\n",
      "Epoch 8/20\terror=0.05060\tTest accuracy: 0.8910Test accuracy: 0.8910\n",
      "Epoch 9/20\terror=0.05020\t\n",
      "Epoch 9/20\terror=0.05020\tTest accuracy: 0.8948Test accuracy: 0.8948\n",
      "Epoch 10/20\terror=0.04989\t\n",
      "Epoch 10/20\terror=0.04989\tTest accuracy: 0.8939Test accuracy: 0.8939\n",
      "Epoch 11/20\terror=0.05012\t\n",
      "Epoch 11/20\terror=0.05012\tTest accuracy: 0.8955Test accuracy: 0.8955\n",
      "Epoch 12/20\terror=0.04998\t\n",
      "Epoch 12/20\terror=0.04998\tTest accuracy: 0.8965Test accuracy: 0.8965\n",
      "Epoch 13/20\terror=0.04964\t\n",
      "Epoch 13/20\terror=0.04964\tTest accuracy: 0.8977Test accuracy: 0.8977\n",
      "Epoch 14/20\terror=0.04971\t\n",
      "Epoch 14/20\terror=0.04971\tTest accuracy: 0.8994Test accuracy: 0.8994\n",
      "Epoch 15/20\terror=0.04983\t\n",
      "Epoch 15/20\terror=0.04983\tTest accuracy: 0.8999Test accuracy: 0.8999\n",
      "Epoch 16/20\terror=0.04954\t\n",
      "Epoch 16/20\terror=0.04954\tTest accuracy: 0.9005Test accuracy: 0.9005\n",
      "Epoch 17/20\terror=0.04955\t\n",
      "Epoch 17/20\terror=0.04955\tTest accuracy: 0.8997Test accuracy: 0.8997\n",
      "Epoch 18/20\terror=0.04941\t\n",
      "Epoch 18/20\terror=0.04941\tTest accuracy: 0.9024Test accuracy: 0.9024\n",
      "Epoch 19/20\terror=0.04943\t\n",
      "Epoch 19/20\terror=0.04943\tTest accuracy: 0.9024Test accuracy: 0.9024\n",
      "Epoch 20/20\terror=0.04932\t\n",
      "Epoch 20/20\terror=0.04932\tTest accuracy: 0.9033Test accuracy: 0.9033"
     ]
    }
   ],
   "source": [
    "inds = list(range(train_image.shape[0]))\n",
    "N = train_image.shape[0]                               # number of training samples\n",
    "\n",
    "loss_hist_4 = []\n",
    "for epoch in range(epochs):\n",
    "    # randomly shuffle the training data at the beginning of each epoch\n",
    "    inds = np.random.permutation(inds)\n",
    "    x_train = train_image[inds]\n",
    "    y_train = train_label[inds]\n",
    "\n",
    "    loss = 0\n",
    "    for b in range(0, N, batch_size):\n",
    "        # get the mini-batch\n",
    "        x_batch = x_train[b: b + batch_size]\n",
    "        y_batch = y_train[b: b + batch_size]\n",
    "\n",
    "        # feed forward\n",
    "        pred = nn.predict(x_batch)\n",
    "\n",
    "        # Error\n",
    "        loss += nn.loss(pred, y_batch) / N\n",
    "\n",
    "        # Back propagation of errors\n",
    "        nn.backward(pred, y_batch)\n",
    "\n",
    "        # Update parameters\n",
    "        nn.optimizer.step()\n",
    "\n",
    "    # record loss per epoch\n",
    "    loss_hist_4.append(loss)\n",
    "\n",
    "    print()\n",
    "    print(\"Epoch %d/%d\\terror=%.5f\" % (epoch + 1, epochs, loss), end='\\t', flush=True)\n",
    "\n",
    "    # Test accuracy\n",
    "    pred = softmax(nn.predict(test_image, mode=False))\n",
    "    y_pred, y_target = np.argmax(pred, axis=1), np.argmax(test_label, axis=1)\n",
    "    accuracy = np.mean(y_pred == y_target)\n",
    "    print(\"Test accuracy: {:.4f}\".format(accuracy), end='')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from activation import Activation\n",
    "from activation import Dropout\n",
    "\n",
    "from utils import *\n",
    "\n",
    "nn = NeuralNetwork()\n",
    "\n",
    "nn.add(FCLayer(train_image.shape[1], train_label.shape[1], initialization='xavier', uniform=True))  # no hidden layers. direct mapping from input images to target labels\n",
    "\n",
    "# Set loss and link to the model\n",
    "loss = CrossEntropyLoss()\n",
    "nn.set_loss(loss)\n",
    "\n",
    "# Set hyperparamters\n",
    "lr = 0.0001                                  # learning rate\n",
    "batch_size = 32                             # mini-batch size\n",
    "epochs = 10                                  # number of epochs\n",
    "\n",
    "# set optimizer and link to the model\n",
    "optimizer = SGD(nn.parameters(), lr=lr, momentum=True)\n",
    "nn.set_optimizer(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\terror=0.01653\t\n",
      "Epoch 1/10\terror=0.01653\tTest accuracy: 0.8949Test accuracy: 0.8949\n",
      "Epoch 2/10\terror=0.01148\t\n",
      "Epoch 2/10\terror=0.01148\tTest accuracy: 0.9111Test accuracy: 0.9111\n",
      "Epoch 3/10\terror=0.01085\t\n",
      "Epoch 3/10\terror=0.01085\tTest accuracy: 0.9132Test accuracy: 0.9132\n",
      "Epoch 4/10\terror=0.00992\t\n",
      "Epoch 4/10\terror=0.00992\tTest accuracy: 0.9139Test accuracy: 0.9139\n",
      "Epoch 5/10\terror=0.01034\t\n",
      "Epoch 5/10\terror=0.01034\tTest accuracy: 0.9192Test accuracy: 0.9192\n",
      "Epoch 6/10\terror=0.00922\t\n",
      "Epoch 6/10\terror=0.00922\tTest accuracy: 0.9185Test accuracy: 0.9185\n",
      "Epoch 7/10\terror=0.00925\t\n",
      "Epoch 7/10\terror=0.00925\tTest accuracy: 0.9165Test accuracy: 0.9165\n",
      "Epoch 8/10\terror=0.00827\t\n",
      "Epoch 8/10\terror=0.00827\tTest accuracy: 0.9199Test accuracy: 0.9199\n",
      "Epoch 9/10\terror=0.00828\t\n",
      "Epoch 9/10\terror=0.00828\tTest accuracy: 0.9174Test accuracy: 0.9174\n",
      "Epoch 10/10\terror=0.00876\t\n",
      "Epoch 10/10\terror=0.00876\tTest accuracy: 0.9198Test accuracy: 0.9198"
     ]
    }
   ],
   "source": [
    "inds = list(range(train_image.shape[0]))\n",
    "N = train_image.shape[0]                               # number of training samples\n",
    "\n",
    "loss_hist_5 = []\n",
    "for epoch in range(epochs):\n",
    "    # randomly shuffle the training data at the beginning of each epoch\n",
    "    inds = np.random.permutation(inds)\n",
    "    x_train = train_image[inds]\n",
    "    y_train = train_label[inds]\n",
    "\n",
    "    loss = 0\n",
    "    for b in range(0, N, batch_size):\n",
    "        # get the mini-batch\n",
    "        x_batch = x_train[b: b + batch_size]\n",
    "        y_batch = y_train[b: b + batch_size]\n",
    "\n",
    "        # feed forward\n",
    "        pred = nn.predict(x_batch)\n",
    "\n",
    "        # Error\n",
    "        loss += nn.loss(pred, y_batch) / N\n",
    "\n",
    "        # Back propagation of errors\n",
    "        nn.backward(pred, y_batch)\n",
    "\n",
    "        # Update parameters\n",
    "        nn.optimizer.step()\n",
    "\n",
    "    # record loss per epoch\n",
    "    loss_hist_5.append(loss)\n",
    "\n",
    "    print()\n",
    "    print(\"Epoch %d/%d\\terror=%.5f\" % (epoch + 1, epochs, loss), end='\\t', flush=True)\n",
    "\n",
    "    # Test accuracy\n",
    "    pred = softmax(nn.predict(test_image, mode=False))\n",
    "    y_pred, y_target = np.argmax(pred, axis=1), np.argmax(test_label, axis=1)\n",
    "    accuracy = np.mean(y_pred == y_target)\n",
    "    print(\"Test accuracy: {:.4f}\".format(accuracy), end='')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from activation import Activation\n",
    "from activation import Dropout\n",
    "\n",
    "from utils import *\n",
    "\n",
    "nn = NeuralNetwork()\n",
    "\n",
    "nn.add(FCLayer(train_image.shape[1], train_label.shape[1], initialization='xavier', uniform=True))  # no hidden layers. direct mapping from input images to target labels\n",
    "\n",
    "# Set loss and link to the model\n",
    "loss = CrossEntropyLoss()\n",
    "nn.set_loss(loss)\n",
    "\n",
    "# Set hyperparamters\n",
    "lr = 0.001                                  # learning rate\n",
    "batch_size = 16                             # mini-batch size\n",
    "epochs = 10                                  # number of epochs\n",
    "\n",
    "# set optimizer and link to the model\n",
    "optimizer = SGD(nn.parameters(), lr=lr, momentum=True)\n",
    "nn.set_optimizer(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\terror=0.02338\t\n",
      "Epoch 1/10\terror=0.02338\tTest accuracy: 0.8944Test accuracy: 0.8944\n",
      "Epoch 2/10\terror=0.02076\t\n",
      "Epoch 2/10\terror=0.02076\tTest accuracy: 0.9075Test accuracy: 0.9075\n",
      "Epoch 3/10\terror=0.02029\t\n",
      "Epoch 3/10\terror=0.02029\tTest accuracy: 0.9061Test accuracy: 0.9061\n",
      "Epoch 4/10\terror=0.01921\t\n",
      "Epoch 4/10\terror=0.01921\tTest accuracy: 0.9111Test accuracy: 0.9111\n",
      "Epoch 5/10\terror=0.01853\t\n",
      "Epoch 5/10\terror=0.01853\tTest accuracy: 0.9079Test accuracy: 0.9079\n",
      "Epoch 6/10\terror=0.01947\t\n",
      "Epoch 6/10\terror=0.01947\tTest accuracy: 0.9127Test accuracy: 0.9127\n",
      "Epoch 7/10\terror=0.01867\t\n",
      "Epoch 7/10\terror=0.01867\tTest accuracy: 0.9088Test accuracy: 0.9088\n",
      "Epoch 8/10\terror=0.01774\t\n",
      "Epoch 8/10\terror=0.01774\tTest accuracy: 0.9094Test accuracy: 0.9094\n",
      "Epoch 9/10\terror=0.01804\t\n",
      "Epoch 9/10\terror=0.01804\tTest accuracy: 0.9095Test accuracy: 0.9095\n",
      "Epoch 10/10\terror=0.02044\t\n",
      "Epoch 10/10\terror=0.02044\tTest accuracy: 0.9109Test accuracy: 0.9109"
     ]
    }
   ],
   "source": [
    "inds = list(range(train_image.shape[0]))\n",
    "N = train_image.shape[0]                               # number of training samples\n",
    "\n",
    "loss_hist_6 = []\n",
    "for epoch in range(epochs):\n",
    "    # randomly shuffle the training data at the beginning of each epoch\n",
    "    inds = np.random.permutation(inds)\n",
    "    x_train = train_image[inds]\n",
    "    y_train = train_label[inds]\n",
    "\n",
    "    loss = 0\n",
    "    for b in range(0, N, batch_size):\n",
    "        # get the mini-batch\n",
    "        x_batch = x_train[b: b + batch_size]\n",
    "        y_batch = y_train[b: b + batch_size]\n",
    "\n",
    "        # feed forward\n",
    "        pred = nn.predict(x_batch)\n",
    "\n",
    "        # Error\n",
    "        loss += nn.loss(pred, y_batch) / N\n",
    "\n",
    "        # Back propagation of errors\n",
    "        nn.backward(pred, y_batch)\n",
    "\n",
    "        # Update parameters\n",
    "        nn.optimizer.step()\n",
    "\n",
    "    # record loss per epoch\n",
    "    loss_hist_6.append(loss)\n",
    "\n",
    "    print()\n",
    "    print(\"Epoch %d/%d\\terror=%.5f\" % (epoch + 1, epochs, loss), end='\\t', flush=True)\n",
    "\n",
    "    # Test accuracy\n",
    "    pred = softmax(nn.predict(test_image, mode=False))\n",
    "    y_pred, y_target = np.argmax(pred, axis=1), np.argmax(test_label, axis=1)\n",
    "    accuracy = np.mean(y_pred == y_target)\n",
    "    print(\"Test accuracy: {:.4f}\".format(accuracy), end='')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing layer structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from activation import Activation\n",
    "from activation import Dropout\n",
    "\n",
    "from utils import *\n",
    "\n",
    "nn = NeuralNetwork()\n",
    "num_layers = 50\n",
    "\n",
    "nn.add(FCLayer(train_image.shape[1], num_layers, initialization='xavier', uniform=True))  # no hidden layers. direct mapping from input images to target labels\n",
    "nn.add(Activation(tanh, tanh_prime))\n",
    "nn.add(FCLayer(num_layers, train_label.shape[1], initialization='xavier', uniform=True))  # no hidden layers. direct mapping from input images to target labels\n",
    "\n",
    "\n",
    "# Set loss and link to the model\n",
    "loss = CrossEntropyLoss()\n",
    "nn.set_loss(loss)\n",
    "\n",
    "# Set hyperparamters\n",
    "lr = 0.001                                  # learning rate\n",
    "batch_size = 16                             # mini-batch size\n",
    "epochs = 10                                  # number of epochs\n",
    "\n",
    "# set optimizer and link to the model\n",
    "optimizer = SGD(nn.parameters(), lr=lr, momentum=True)\n",
    "nn.set_optimizer(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\terror=0.02047\t\n",
      "Epoch 1/10\terror=0.02047\tTest accuracy: 0.9274Test accuracy: 0.9274\n",
      "Epoch 2/10\terror=0.01266\t\n",
      "Epoch 2/10\terror=0.01266\tTest accuracy: 0.9399Test accuracy: 0.9399\n",
      "Epoch 3/10\terror=0.01020\t\n",
      "Epoch 3/10\terror=0.01020\tTest accuracy: 0.9585Test accuracy: 0.9585\n",
      "Epoch 4/10\terror=0.00912\t\n",
      "Epoch 4/10\terror=0.00912\tTest accuracy: 0.9515Test accuracy: 0.9515\n",
      "Epoch 5/10\terror=0.00880\t\n",
      "Epoch 5/10\terror=0.00880\tTest accuracy: 0.9601Test accuracy: 0.9601\n",
      "Epoch 6/10\terror=0.00661\t\n",
      "Epoch 6/10\terror=0.00661\tTest accuracy: 0.9600Test accuracy: 0.9600\n",
      "Epoch 7/10\terror=0.00710\t\n",
      "Epoch 7/10\terror=0.00710\tTest accuracy: 0.9636Test accuracy: 0.9636"
     ]
    }
   ],
   "source": [
    "inds = list(range(train_image.shape[0]))\n",
    "N = train_image.shape[0]                               # number of training samples\n",
    "\n",
    "loss_hist_6 = []\n",
    "for epoch in range(epochs):\n",
    "    # randomly shuffle the training data at the beginning of each epoch\n",
    "    inds = np.random.permutation(inds)\n",
    "    x_train = train_image[inds]\n",
    "    y_train = train_label[inds]\n",
    "\n",
    "    loss = 0\n",
    "    for b in range(0, N, batch_size):\n",
    "        # get the mini-batch\n",
    "        x_batch = x_train[b: b + batch_size]\n",
    "        y_batch = y_train[b: b + batch_size]\n",
    "\n",
    "        # feed forward\n",
    "        pred = nn.predict(x_batch)\n",
    "\n",
    "        # Error\n",
    "        loss += nn.loss(pred, y_batch) / N\n",
    "\n",
    "        # Back propagation of errors\n",
    "        nn.backward(pred, y_batch)\n",
    "\n",
    "        # Update parameters\n",
    "        nn.optimizer.step()\n",
    "\n",
    "    # record loss per epoch\n",
    "    loss_hist_6.append(loss)\n",
    "\n",
    "    print()\n",
    "    print(\"Epoch %d/%d\\terror=%.5f\" % (epoch + 1, epochs, loss), end='\\t', flush=True)\n",
    "\n",
    "    # Test accuracy\n",
    "    pred = softmax(nn.predict(test_image, mode=False))\n",
    "    y_pred, y_target = np.argmax(pred, axis=1), np.argmax(test_label, axis=1)\n",
    "    accuracy = np.mean(y_pred == y_target)\n",
    "    print(\"Test accuracy: {:.4f}\".format(accuracy), end='')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layers\tOptimizer\tEpochs\tLearning Rate\tBatch Size\tAccuracy\n",
    "FCN\tAdam\t10\t0.001\t32\t0.9213\n",
    "FCN, Relu \tAdam\t10\t0.001\t32\t0.4477\n",
    "FCN, Tanh\tAdam\t10\t0.001\t32\t0.9088\n",
    "FCN\tAdam\t10\t0.0001\t32\t0.9129\n",
    "FCN\tAdam\t20\t0.0001\t32\t0.9175\n",
    "FCN, Sigmoid\tAdam\t20\t0.0001\t32\t0.9033\n",
    "FCN\tSGD\t10\t0.0001\t32\t0.9198\n",
    "FCN, tanh, FCN\tSGD\t10\t0.001\t16\t0.9636"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|\tLayers\t|\tOptimizer\t|\tEpochs\t|\tLearning Rate\t|\tBatch Size\t|\tAccuracy\n",
    "|\t---------------\t|\t---------------\t|\t---------------\t|\t---------------\t|\t---------------\t|\t---------------\n",
    "|\tFCN\t|\tAdam\t|\t10\t|\t0.001\t|\t32\t|\t0.9213\n",
    "|\tFCN, Relu \t|\tAdam\t|\t10\t|\t0.001\t|\t32\t|\t0.4477\n",
    "|\tFCN, Tanh\t|\tAdam\t|\t10\t|\t0.001\t|\t32\t|\t0.9088\n",
    "|\tFCN\t|\tAdam\t|\t10\t|\t0.0001\t|\t32\t|\t0.9129\n",
    "|\tFCN\t|\tAdam\t|\t20\t|\t0.0001\t|\t32\t|\t0.9175\n",
    "|\tFCN, Sigmoid\t|\tAdam\t|\t20\t|\t0.0001\t|\t32\t|\t0.9033\n",
    "|\tFCN\t|\tSGD\t|\t10\t|\t0.0001\t|\t32\t|\t0.9198\n",
    "|\tFCN, tanh, FCN\t|\tSGD\t|\t10\t|\t0.001\t|\t16\t|\t0.9636"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
